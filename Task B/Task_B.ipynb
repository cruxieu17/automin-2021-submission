{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TASKB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vflZe0BU0DVZ",
        "m1dRaldhrGQa",
        "1dOWCyokbS07",
        "m7usmhcQ9_GO",
        "G8k7B0sxl9A0",
        "tYTkSWCGl5XC",
        "61SFEpI660d0",
        "QUFLiC1grr4N",
        "4e-aZwhpfNKO"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVqXcqpwXpxj",
        "outputId": "527c32df-338e-42f0-802e-e28572268570"
      },
      "source": [
        "import os\n",
        "len(os.listdir('/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/train'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "566"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNv-4SMPQcoT",
        "outputId": "01501ad6-1568-46e8-b141-821f3cfc6260"
      },
      "source": [
        "minutes1 = open('/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/train/task_B_en_train_5537/task_B_en_train_5537_minutes.txt', 'r')\n",
        "minutes1 = minutes1.readlines()\n",
        "print(len(minutes1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH2A5aHCTuor",
        "outputId": "cb713087-d279-4610-b74b-e15a3d6c55d4"
      },
      "source": [
        "transcripts1 = open('/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/train/task_B_en_train_5537/task_B_en_train_5537_transcript.txt', 'r')\n",
        "transcripts1 = transcripts1.readlines()\n",
        "print(len(transcripts1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na2JV5n6LUSk"
      },
      "source": [
        "import re\n",
        " \n",
        "def rem_boundries(wordList):\n",
        " \n",
        "  processed_list = []\n",
        " \n",
        "  reg_Ex = [r\"\\(\", r\"\\)\", r\"\\[\", r\"]\"]\n",
        " \n",
        "  for word in wordList:\n",
        "    for exp in reg_Ex:\n",
        "      word = re.sub(exp, '', word)\n",
        "    processed_list.append(word)\n",
        " \n",
        "  return processed_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omyP-hfnNKQG"
      },
      "source": [
        "def brac_match(reg_ex, TextList):\n",
        "  \n",
        "  processed_list = []\n",
        " \n",
        "  for line in TextList:\n",
        "    for exp in reg_ex:\n",
        "      result = re.findall(exp, line)\n",
        "      if len(result) > 0:\n",
        "        for word in result:\n",
        "          if word not in processed_list:\n",
        "            processed_list.append(word)\n",
        " \n",
        "  return processed_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo07m1tHDiY-"
      },
      "source": [
        "import re \n",
        " \n",
        "def get_brac_cnt(Textlist):\n",
        "  \n",
        "  Reg_Ex = [r\"\\(PERSON\\d+\\)\", r\"\\[PERSON\\d+\\]\"] \n",
        "  Reg_Ex_ = [r\"\\[ORGANIZATION\\d+\\]\", r\"\\[PROJECT\\d+\\]\"]\n",
        "  \n",
        "  List_A = brac_match(Reg_Ex, Textlist)\n",
        "  List_A =  rem_boundries(List_A)\n",
        " \n",
        "  List_B = brac_match(Reg_Ex_, Textlist)\n",
        "  List_B =  rem_boundries(List_B)\n",
        " \n",
        "  if len(List_B) > len(List_A):\n",
        "    return List_B\n",
        " \n",
        "  return list(set(List_A))\n",
        " \n",
        "# x, y = get_brac_cnt(minutes), get_brac_cnt(transcripts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yFu151GLdjc"
      },
      "source": [
        "def chk_person_match(meet_br_cnt, trans_br_cnt):\n",
        " \n",
        "  similar_cnt = []\n",
        " \n",
        "  for word in meet_br_cnt:\n",
        "    if word in trans_br_cnt:\n",
        "      similar_cnt.append(word)\n",
        " \n",
        "  return similar_cnt\n",
        " \n",
        "# c = chk_person_match(x, y)\n",
        "# c, len(c), len(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooUoF3Zwjyr5"
      },
      "source": [
        "import re\n",
        " \n",
        "def remove_cntsqbr(text_list):\n",
        "  \n",
        "  new_list = []\n",
        " \n",
        "  for word in text_list:\n",
        "    new_list.append(re.sub(r\"( +)\\[(.*?)\\]\", '', word))\n",
        " \n",
        "  return new_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIXKBnjwbjw",
        "outputId": "cef4dd0d-1418-4250-cc41-ce639814f64c"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        " \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        " \n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYnoRqm2z4h4"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        " \n",
        "def remove_punctuation(text):\n",
        " \n",
        "  tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        " \n",
        "  return ' '.join(tokenizer.tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeJP0hd0zUd2"
      },
      "source": [
        "def remove_stopwords(stop_words, text):\n",
        " \n",
        "  wordsList = word_tokenize(text)\n",
        " \n",
        "  wordsList = [w for w in wordsList if w not in stop_words]\n",
        " \n",
        "  return wordsList"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0SmahxG0Ia4"
      },
      "source": [
        "def add_postag(word_tokens):\n",
        "  \n",
        "  tagged = nltk.pos_tag(word_tokens)\n",
        " \n",
        "  return tagged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jOcV9YCMRMP",
        "outputId": "a9d1d0d4-4788-42ba-9b14-3c3b77908eaa"
      },
      "source": [
        "text = \"I got model description from [PERSON16]. Still waiting for training reproduction scripts for easy training setup\"\n",
        "text = remove_punctuation(text)\n",
        "word_tokens = remove_stopwords(stop_words, text)\n",
        "tag_list = add_postag(word_tokens)\n",
        "nouns = get_NNS(tag_list)\n",
        "print(nouns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['model', 'description', 'reproduction', 'easy', 'setup']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU_b3zWJFMOT",
        "outputId": "9cef1ccb-c412-4840-f619-73bbc56f2f10"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atDGIIuoQDtQ"
      },
      "source": [
        "import spacy\n",
        "\n",
        "def add_postag_spacy(text):\n",
        "\n",
        "  tagged = []\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "  word_tokens = nlp(text)\n",
        "\n",
        "  for token in word_tokens:\n",
        "    tagged.append((token, token.pos_))\n",
        "\n",
        "  return tagged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJkFqQOpRPug"
      },
      "source": [
        "def get_NOUNS_spacy(tagged_tokens):\n",
        "\n",
        "  Extracted_Nouns = []\n",
        "\n",
        "  Extracted_Nouns = [word for word, tag in tagged_tokens if tag == 'NOUN']\n",
        "\n",
        "  return Extracted_Nouns\n",
        "\n",
        "# get_NOUNS_spacy(tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGwfqud1wn8u"
      },
      "source": [
        "def aggregate_nouns_spacy(textList):\n",
        "\n",
        "  tot_nouns = []\n",
        "\n",
        "  for text in textList:\n",
        "    text = remove_punctuation(text)\n",
        "    tag_list = add_postag_spacy(text)\n",
        "    nouns = get_NOUNS_spacy(tag_list)\n",
        "    tot_nouns.extend(nouns)\n",
        "\n",
        "  tot_nouns = [word for word in tot_nouns if len(word) > 6]\n",
        "\n",
        "  return tot_nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_aH1q0H7P3l"
      },
      "source": [
        "def get_NNS(tagged_tokens):\n",
        " \n",
        "  Extracted_Nouns = []\n",
        "    \n",
        "  # Extracted_Nouns = [word for word, tag in tagged_tokens if tag == 'NN' or tag == 'NNS']\n",
        "  Extracted_Nouns = [word for word, tag in tagged_tokens if tag == 'NN' or tag == 'JJ']\n",
        "  # Extracted_Nouns = [word for word, tag in tagged_tokens if tag == 'NNP' or tag == \"NN\"]\n",
        " \n",
        "  return Extracted_Nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRph-PwX8-wo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "1d6b8f01-0fc7-4b08-f485-98b4dc669ed1"
      },
      "source": [
        "def aggregate_nouns(stop_words, textList):\n",
        " \n",
        "  tot_nouns = []\n",
        " \n",
        "  for text in textList:\n",
        "    text = remove_punctuation(text)\n",
        "    word_tokens = remove_stopwords(stop_words, text)\n",
        "    tag_list = add_postag(word_tokens)\n",
        "    nouns = get_NNS(tag_list)\n",
        "    tot_nouns.extend(nouns)\n",
        " \n",
        "  tot_nouns = [word for word in tot_nouns if len(word) > 5]\n",
        " \n",
        "  return tot_nouns\n",
        " \n",
        "x = aggregate_nouns(stop_words, transcripts)\n",
        "z = aggregate_nouns(stop_words, minutes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8f798e22ba00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtot_nouns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_nouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_nouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transcripts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cw_JbLbc2GT"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuMEX-XZP2Yr"
      },
      "source": [
        "def Counter_Transcripts(transcript):\n",
        " \n",
        "  return Counter(transcript)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOyOyHMfTuT_"
      },
      "source": [
        "def restrict_counter(Counter_Transcript):\n",
        " \n",
        "    prepro_counter = dict()\n",
        " \n",
        "    for key, value in Counter_Transcript.items():\n",
        " \n",
        "      # if value < 10:\n",
        "      #   prepro_counter[key] = value\n",
        " \n",
        "      if value > 10:\n",
        "        prepro_counter[key] = 10\n",
        "      else:\n",
        "        prepro_counter[key] = value\n",
        " \n",
        " \n",
        "    return prepro_counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdPm_Wt6fil8"
      },
      "source": [
        "def get_similar_nouns(minute_nouns, transcript_nouns):\n",
        " \n",
        "  similar_nouns = [w for w in minute_nouns if w in transcript_nouns]\n",
        " \n",
        "  return similar_nouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd6aoCF6mHtZ"
      },
      "source": [
        "def meet_word_count(minute_nouns, transcript_nouns_Counter):\n",
        " \n",
        "  transcript_Counter = restrict_counter(transcript_nouns_Counter)\n",
        " \n",
        "  trans_nouns_set = list(transcript_Counter.keys())\n",
        "  trans_nouns_count = list(transcript_Counter.values())\n",
        " \n",
        "  count_p_index = []\n",
        " \n",
        "  for word in minute_nouns:\n",
        "    for idx, t_word in enumerate(trans_nouns_set):\n",
        "      if word == t_word:\n",
        "        count_p_index.append(trans_nouns_count[idx])\n",
        " \n",
        "  return count_p_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPWoErVJMqsM",
        "outputId": "0e9f59eb-a28a-4886-fa8e-37d85e616ff6"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes)\n",
        "transcript = remove_cntsqbr(transcripts)  \n",
        " \n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        " \n",
        "# Apply Counter to Transcripts\n",
        "Transcript_nouns_Counter = Counter(Transcript_nouns)\n",
        " \n",
        "# check the word count corresponding to similarity of minute nouns in transcript nouns\n",
        "word_count = meet_word_count(Minute_nouns, Transcript_nouns_Counter)\n",
        "print(word_count)\n",
        " \n",
        "print(calculate_Avg(word_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4, 1, 1, 3, 3, 8, 4, 2]\n",
            "3.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8EhwAEsY73V"
      },
      "source": [
        "import torch\n",
        " \n",
        "def calculate_Avg(minute_Count):\n",
        " \n",
        "  c_Tensor = torch.Tensor(minute_Count)\n",
        " \n",
        "  mean = torch.mean(c_Tensor)\n",
        " \n",
        "  return mean.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck1h7pUph2b4"
      },
      "source": [
        "def concat_nouns(minute_list, transcript_list):\n",
        " \n",
        "  Nounlist_A = list(set(minute_list))\n",
        " \n",
        "  trans_Counter = Counter_Transcripts(transcript_list)\n",
        "  Trans_dict = restrict_counter(trans_Counter)  \n",
        "  Nounlist_B = Trans_dict.keys()\n",
        " \n",
        "  minute_str = ' '.join(Nounlist_A)\n",
        "  transcript_str = ' '.join(Nounlist_B)\n",
        " \n",
        "  return minute_str, transcript_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmNpLXhcinu8"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes)\n",
        "transcript = remove_cntsqbr(transcripts)  \n",
        " \n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        " \n",
        "minute_str, transcript_str = concat_nouns(Minute_nouns, Transcript_nouns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17_sCoCza5Z3"
      },
      "source": [
        "## Generate Label and File Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERaL4Qp-gaDX",
        "outputId": "6f8556e6-3d03-4bb3-da0c-f1ffb27ea8bf"
      },
      "source": [
        "cd /content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmRaS-q1gkNv"
      },
      "source": [
        "import os\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/'\n",
        "train_dir = os.path.join(root_dir, 'train/')\n",
        "dev_dir = os.path.join(root_dir, 'dev/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS7J8pkduP1v"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "train_tsv = pd.read_csv('/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/EN_train_task_b.tsv', sep='\\t')\n",
        "\n",
        "dir = list(train_tsv['Directory'])\n",
        "labels = list(train_tsv['Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFwymQ25z65J",
        "outputId": "c53c9ef0-2780-403a-fdab-33e9c871695f"
      },
      "source": [
        "true_labels = [label for label in labels if label == True]\n",
        "print(len(true_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VUrV337WKDu",
        "outputId": "43b30d9e-e295-48fb-dc4e-e66e4bf3ac08"
      },
      "source": [
        "print(len(os.listdir(train_dir)) + len(os.listdir(dev_dir)))\n",
        "print(len(os.listdir(train_dir)))\n",
        "print(len(os.listdir(dev_dir)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "846\n",
            "566\n",
            "280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irDSyZkBb5sJ"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "dev_tsv = pd.read_csv('/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/EN_dev_task_b.tsv', sep='\\t')\n",
        "\n",
        "d_dir = list(dev_tsv['Directory'])\n",
        "d_labels = list(dev_tsv['Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3p1ThvA0HAB",
        "outputId": "39431546-27ca-4a7a-8533-267f88e9bc49"
      },
      "source": [
        "d_true_labels = [label for label in d_labels if label == True]\n",
        "print(len(d_true_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgGjlx8RtzCI"
      },
      "source": [
        "def return_label(key, labels, dir):\n",
        "\n",
        "  label = None\n",
        "  for idx, i in enumerate(dir):\n",
        "    if i == key:\n",
        "      label = labels[idx]\n",
        "  return label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFPA_MVMgREU"
      },
      "source": [
        "transcript_files = []\n",
        "minutes_files = []\n",
        " \n",
        "train_folder = os.listdir(train_dir)\n",
        " \n",
        "for folder in train_folder:\n",
        " \n",
        "  root_file = train_dir + f'{folder}'\n",
        "  try:\n",
        "    t_file = root_file + f'/{folder}_transcript.txt'\n",
        "    open(t_file, 'r').readlines()\n",
        "    m_file = root_file + f'/{folder}_minutes.txt'\n",
        "    open(m_file, 'r').readlines()\n",
        " \n",
        "    transcript_files.append(t_file)\n",
        "    minutes_files.append(m_file)\n",
        " \n",
        "  except Exception as e:\n",
        "    print(f'Cannot open file in folder: {folder}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhKiFdNRbz3G"
      },
      "source": [
        "dev_folder = os.listdir(dev_dir)\n",
        "\n",
        "for folder in dev_folder:\n",
        "\n",
        "  root_file = dev_dir + f'{folder}'\n",
        "  try:\n",
        "    t_file = root_file + f'/{folder}_transcript.txt'\n",
        "    open(t_file, 'r').readlines()\n",
        "    m_file = root_file + f'/{folder}_minutes.txt'\n",
        "    open(m_file, 'r').readlines()\n",
        "\n",
        "    transcript_files.append(t_file)\n",
        "    minutes_files.append(m_file)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f'Cannot open file in folder: {folder}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F2LRW3Bz1HU"
      },
      "source": [
        "len(transcript_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut7aqBTIdobK"
      },
      "source": [
        "# transit from train->dev set\n",
        "import re\n",
        "\n",
        "def flag_train_2_dev(text):\n",
        "  \n",
        "  result = re.findall(r'dev', text)\n",
        "  if len(result) > 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgphoNbncado"
      },
      "source": [
        "Labels = []\n",
        "\n",
        "for file_names in transcript_files:\n",
        "\n",
        "  Flag = flag_train_2_dev(file_names)\n",
        "\n",
        "  if Flag:\n",
        "    print('Parsing dev files')\n",
        "    key = file_names[-19: -15]\n",
        "    print(key)\n",
        "    try:\n",
        "      key = int(key)\n",
        "      Labels.append(return_label(key, d_labels, d_dir))\n",
        "    except Exception as e:\n",
        "      print(f'Cannot convert key in file {file_names} to int')\n",
        "\n",
        "  else:\n",
        "    print('Parsing train files')\n",
        "    key = file_names[-19: -15]\n",
        "    try:\n",
        "      key = int(key)\n",
        "      Labels.append(return_label(key, labels, dir))\n",
        "    except Exception as e:\n",
        "      print(f'Cannot convert key in file {file_names} to int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vflZe0BU0DVZ"
      },
      "source": [
        "## Calculate Score 1 for True Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fgJfxH30CoE"
      },
      "source": [
        "score_1_results = []\n",
        "\n",
        "for idx, val in enumerate(Labels):\n",
        "  print(f'Iterating over file: {idx}')\n",
        "  try:\n",
        "    minutes = open(minutes_files[idx], 'r').readlines()\n",
        "    transcript = open(transcript_files[idx], 'r').readlines()\n",
        "    pred_label = cnt_aggregator(minutes, transcript)\n",
        "    score_1_results.append(pred_label)\n",
        "  except Exception as e:\n",
        "    print('Ignoring this files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJzeGfTObNF6"
      },
      "source": [
        "## Calculate Score 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1dRaldhrGQa"
      },
      "source": [
        "### Testing something related to Score 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqMP8NcZneYS"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV5ihzbrnpGh"
      },
      "source": [
        "def lowercase(word_list):\n",
        "\n",
        "  lower_list = []\n",
        "\n",
        "  for word in word_list:\n",
        "    lower_list.append(word.lower())\n",
        "\n",
        "  return lower_list\n",
        "\n",
        "def apply_stemming(word_list, flag=True):\n",
        "  \n",
        "  if flag:\n",
        "    word_list = list(set(word_list))\n",
        "\n",
        "  ps = PorterStemmer()  \n",
        "\n",
        "  stemmed_words = []\n",
        "\n",
        "  for word in word_list:\n",
        "    stemmed_words.append(ps.stem(word))\n",
        "\n",
        "  if flag:\n",
        "    stemmed_words = list(set(stemmed_words))\n",
        "\n",
        "  return stemmed_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRAgbhrDpuc8"
      },
      "source": [
        "def match_words(Minute_nouns, Transcript_nouns):\n",
        "\n",
        "  Minute_nouns = list(set(Minute_nouns))  \n",
        "  Transcript_nouns = list(set(Transcript_nouns))\n",
        "\n",
        "  Count = 0\n",
        "  for word in Minute_nouns:\n",
        "    if word in Transcript_nouns:\n",
        "      Count += 1\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7AHgKtBXnhr"
      },
      "source": [
        "To_remove_list = ['something', 'meeting', 'transcript', 'arrival', 'system', 'suggestion', 'annotation']\n",
        "\n",
        "def remove_from(text_list):\n",
        "\n",
        "  text_list = list(set(lowercase(text_list)))\n",
        "\n",
        "  sample = []\n",
        "\n",
        "  for word in text_list:\n",
        "    if word not in To_remove_list:\n",
        "      sample.append(word)\n",
        "\n",
        "  return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATykTFlKlwQ8",
        "outputId": "b54e9c56-9f10-4111-e7c2-5de5b7c594b3"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes1)\n",
        "transcript = remove_cntsqbr(transcripts1)  \n",
        "\n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        "\n",
        "Minute_nouns = remove_from(Minute_nouns)\n",
        "Transcript_nouns = remove_from(Transcript_nouns)\n",
        "\n",
        "# Minute_nouns = apply_stemming(Minute_nouns)\n",
        "# Transcript_nouns = apply_stemming(Transcript_nouns, False)\n",
        "\n",
        "print(list(set(Minute_nouns)))\n",
        "\n",
        "Minute_nouns = list(set(Minute_nouns))\n",
        "Transcript_nouns = list(set(Transcript_nouns))\n",
        "Count = 0\n",
        "for word in Minute_nouns:\n",
        "  if word in Transcript_nouns:\n",
        "    # print(word)\n",
        "    Count+=1\n",
        "  else:\n",
        "    pass\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['person', 'source', 'combination', 'translation', 'speaker', 'language', 'combinaton']\n",
            "combination\n",
            "combinaton\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JP5UohqSr9x",
        "outputId": "44f29f15-d4cc-474d-c56a-55f2c4710f8e"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes2)\n",
        "transcript = remove_cntsqbr(transcripts2)  \n",
        "\n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        "\n",
        "\n",
        "Minute_nouns = remove_from(Minute_nouns)\n",
        "Transcript_nouns = remove_from(Transcript_nouns)\n",
        "\n",
        "# Minute_nouns = apply_stemming(Minute_nouns)\n",
        "# Transcript_nouns = apply_stemming(Transcript_nouns, False)\n",
        "\n",
        "print(list(set(Minute_nouns)))\n",
        "\n",
        "Minute_nouns = list(set(Minute_nouns))\n",
        "Transcript_nouns = list(set(Transcript_nouns))\n",
        "Count = 0\n",
        "for word in Minute_nouns:\n",
        "  if word in Transcript_nouns:\n",
        "    # print(word)\n",
        "    Count+=1\n",
        "  else:\n",
        "    pass\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['lemmatization', 'constraint', 'implementation', 'payment', 'expression', 'architecture', 'baseline', 'document', 'difference', 'anything', 'achieve', 'research', 'lemmas', 'translation', 'quality', 'confidence', 'approach', 'versus', 'graphs', 'source', 'budget', 'estimation']\n",
            "payment\n",
            "expression\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJpfOtCXSsc2",
        "outputId": "8c86cdd4-5275-4edb-f9db-f1e1310a2dd8"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes3)\n",
        "transcript = remove_cntsqbr(transcripts3)  \n",
        "\n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        "\n",
        "\n",
        "Minute_nouns = remove_from(Minute_nouns)\n",
        "Transcript_nouns = remove_from(Transcript_nouns)\n",
        "\n",
        "# Minute_nouns = apply_stemming(Minute_nouns)\n",
        "# Transcript_nouns = apply_stemming(Transcript_nouns, False)\n",
        "\n",
        "print(list(set(Minute_nouns)))\n",
        "\n",
        "Minute_nouns = list(set(Minute_nouns))\n",
        "Transcript_nouns = list(set(Transcript_nouns))\n",
        "Count = 0\n",
        "for word in Minute_nouns:\n",
        "  if word in Transcript_nouns:\n",
        "    print(word)\n",
        "    Count+=1\n",
        "  else:\n",
        "    pass\n",
        "    # print(word)\n",
        "\n",
        "print(Count, len(Minute_nouns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['discussion', 'development', 'involvement', 'compromise', 'clarification', 'interest', 'advice', 'cluster', 'therefore', 'synchronisation', 'specialise', 'progress', 'moment', 'summarization', 'everything', 'relation', 'research', 'organisation', 'creation', 'repository', 'aggregate', 'release', 'literature', 'storage', 'workload', 'review', 'format', 'decision', 'agreement', 'information', 'privacy']\n",
            "moment\n",
            "everything\n",
            "2 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp4KVOenaqBp",
        "outputId": "bab14a58-e90d-4c2d-89e9-d933bbd03d64"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes4)\n",
        "transcript = remove_cntsqbr(transcripts4)  \n",
        "\n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        "\n",
        "\n",
        "Minute_nouns = remove_from(Minute_nouns)\n",
        "Transcript_nouns = remove_from(Transcript_nouns)\n",
        "\n",
        "# Minute_nouns = apply_stemming(Minute_nouns)\n",
        "# Transcript_nouns = apply_stemming(Transcript_nouns, False)\n",
        "\n",
        "print(list(set(Minute_nouns)))\n",
        "\n",
        "Minute_nouns = list(set(Minute_nouns))\n",
        "Transcript_nouns = list(set(Transcript_nouns))\n",
        "Count = 0\n",
        "for word in Minute_nouns:\n",
        "  if word in Transcript_nouns:\n",
        "    # print(word)\n",
        "    Count+=1\n",
        "  else:\n",
        "    pass\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['discussion', 'development', 'involvement', 'compromise', 'clarification', 'interest', 'advice', 'cluster', 'therefore', 'synchronisation', 'specialise', 'progress', 'moment', 'summarization', 'everything', 'relation', 'research', 'organisation', 'creation', 'repository', 'aggregate', 'release', 'literature', 'storage', 'workload', 'review', 'format', 'decision', 'agreement', 'information', 'privacy']\n",
            "discussion\n",
            "development\n",
            "involvement\n",
            "compromise\n",
            "clarification\n",
            "interest\n",
            "advice\n",
            "therefore\n",
            "synchronisation\n",
            "specialise\n",
            "progress\n",
            "moment\n",
            "summarization\n",
            "relation\n",
            "research\n",
            "organisation\n",
            "creation\n",
            "repository\n",
            "aggregate\n",
            "release\n",
            "literature\n",
            "storage\n",
            "workload\n",
            "review\n",
            "decision\n",
            "agreement\n",
            "privacy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVgAcx2Aaq1F",
        "outputId": "27185269-b496-44b6-c372-0d6f5b47f179"
      },
      "source": [
        "# Remove the content within square brackets \n",
        "minute = remove_cntsqbr(minutes5)\n",
        "transcript = remove_cntsqbr(transcripts5)  \n",
        "\n",
        "# Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        "\n",
        "\n",
        "Minute_nouns = remove_from(Minute_nouns)\n",
        "Transcript_nouns = remove_from(Transcript_nouns)\n",
        "\n",
        "# Minute_nouns = apply_stemming(Minute_nouns)\n",
        "# Transcript_nouns = apply_stemming(Transcript_nouns, False)\n",
        "\n",
        "print(list(set(Minute_nouns)))\n",
        "\n",
        "Minute_nouns = list(set(Minute_nouns))\n",
        "Transcript_nouns = list(set(Transcript_nouns))\n",
        "Count = 0\n",
        "for word in Minute_nouns:\n",
        "  if word in Transcript_nouns:\n",
        "    # print(word)\n",
        "    Count+=1\n",
        "  else:\n",
        "    pass\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['review', 'metaform', 'success', 'project', 'milestone', 'anything', 'dissemination']\n",
            "metaform\n",
            "success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJZv54zFq80E"
      },
      "source": [
        "### Back to Score 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lILE8n9YEtr"
      },
      "source": [
        "def cnt_aggregator(minute, transcript, threshold = 0.8):\n",
        "\n",
        "  minute_cnt = get_brac_cnt(minute)\n",
        "  if len(minute_cnt) == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    trans_cnt = get_brac_cnt(transcript)\n",
        "    match = chk_person_match(minute_cnt, trans_cnt)\n",
        "    m_len = len(match)\n",
        "    min_len = len(minute_cnt)\n",
        "    score = len(match)/len(minute_cnt)\n",
        "    if score > threshold:\n",
        "      return 1\n",
        "    else: \n",
        "      return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYarngQEcc6U"
      },
      "source": [
        "score_1_results = []\n",
        "\n",
        "for idx, val in enumerate(Labels):\n",
        "  print(f'Iterating over file: {idx}')\n",
        "  try:\n",
        "    minutes = open(minutes_files[idx], 'r').readlines()\n",
        "    transcript = open(transcript_files[idx], 'r').readlines()\n",
        "    pred_label = cnt_aggregator(minutes, transcript)\n",
        "    score_1_results.append(pred_label)\n",
        "  except Exception as e:\n",
        "    print('Ignoring this files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dOWCyokbS07"
      },
      "source": [
        "### Check Confusion with different threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HQl_DA9bpn4",
        "outputId": "77745660-819c-469f-e3b0-53fe2dca254e"
      },
      "source": [
        "Thresholds = [0.7, 0.75, 0.8, 0.85]\n",
        "Scores = dict()\n",
        "\n",
        "for thres in Thresholds:\n",
        "\n",
        "  score_1_results = []\n",
        "\n",
        "  print(f'Threshold: {thres}')\n",
        "  for idx, val in enumerate(Labels):\n",
        "    try:\n",
        "      minutes = open(minutes_files[idx], 'r').readlines()\n",
        "      transcript = open(transcript_files[idx], 'r').readlines()\n",
        "      pred_label = cnt_aggregator(minutes, transcript, thres)\n",
        "      score_1_results.append(pred_label)\n",
        "    except Exception as e:\n",
        "      print('Ignoring this files')\n",
        "\n",
        "  Scores[f'thres_{thres}'] = score_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Threshold: 0.7\n",
            "Threshold: 0.75\n",
            "Threshold: 0.8\n",
            "Threshold: 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCR0jy_YdFp5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzOvQQ6sj_UM",
        "outputId": "89d9513c-6fa3-4864-8535-865f8565d69e"
      },
      "source": [
        "Scores.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['thres_0.7', 'thres_0.75', 'thres_0.8', 'thres_0.85'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11vNCxSPeK3W",
        "outputId": "ffac82e9-c66d-4ed7-b9d5-a5829d969ebd"
      },
      "source": [
        "cf_val = {\n",
        "    'Threshold': [],\n",
        "    'tn': [],\n",
        "    'fp': [],\n",
        "    'fn': [],\n",
        "    'tp': []\n",
        "}\n",
        "\n",
        "for thres in Thresholds:\n",
        "\n",
        "  cf_val['Threshold'].append(thres)\n",
        "\n",
        "  y_pred = Scores[f'thres_{thres}']\n",
        "  y_true = Labels\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  cf_val['tn'].append(tn)\n",
        "  cf_val['fp'].append(fp)\n",
        "  cf_val['fn'].append(fn)\n",
        "  cf_val['tp'].append(tp)\n",
        "\n",
        "\n",
        "cf_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Threshold': [0.7, 0.75, 0.8, 0.85],\n",
              " 'fn': [34, 40, 44, 46],\n",
              " 'fp': [323, 283, 245, 217],\n",
              " 'tn': [405, 445, 483, 511],\n",
              " 'tp': [81, 75, 71, 69]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad5iQnJP9P_U"
      },
      "source": [
        "## Calculate Score 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OTBkvhF8gFf",
        "outputId": "aaf4f4dc-5fdb-4381-863d-1fd3a2d80f02"
      },
      "source": [
        "# get the nouns list for both minutes and Transcript\n",
        "# apply aggregate function\n",
        "\n",
        "def overall_aggregator(minute, transcript, stopwords):\n",
        "\n",
        "  # Remove the content within square brackets \n",
        "  minute = remove_cntsqbr(minute)\n",
        "  transcript = remove_cntsqbr(transcript)  \n",
        "\n",
        "  # Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "  Minute_nouns = aggregate_nouns(stopwords, minute)\n",
        "  Transcript_nouns = aggregate_nouns(stopwords, transcript)\n",
        "\n",
        "  # Apply Counter to Transcripts\n",
        "  Transcript_nouns_Counter = Counter(Transcript_nouns)\n",
        "\n",
        "  # check the word count corresponding to similarity of minute nouns in transcript nouns\n",
        "  word_count = meet_word_count(Minute_nouns, Transcript_nouns_Counter)\n",
        "\n",
        "  # Calculat Average distinct word count of minutes nouns in transcript nouns\n",
        "  avg_value = calculate_Avg(word_count)\n",
        "\n",
        "  return avg_value\n",
        "\n",
        "average = overall_aggregator(minutes, transcripts, stop_words)\n",
        "\n",
        "overall_aggregator(minutes, transcripts, stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.857142925262451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E79lmb-OYZKt"
      },
      "source": [
        "import os\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/'\n",
        "train_dir = os.path.join(root_dir, 'train/')\n",
        "dev_dir = os.path.join(root_dir, 'dev/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAxdv6lhEzWG"
      },
      "source": [
        "score_2_results = []\n",
        "\n",
        "for idx, val in enumerate(Labels):\n",
        "  print(f'Iterating over file: {idx}')\n",
        "  try:\n",
        "    minutes = open(minutes_files[idx], 'r').readlines()\n",
        "    transcript = open(transcript_files[idx], 'r').readlines()\n",
        "    avg_val = overall_aggregator(minute=minutes, transcript=transcript, stopwords=stop_words)\n",
        "    score_2_results.append(avg_val)\n",
        "  except Exception as e:\n",
        "    print('Ignoring this files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCSQcSOOjnwZ"
      },
      "source": [
        "## Calculate Score 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Jj9Ujm-EOj"
      },
      "source": [
        "### Defining Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX3yx-9vj6Lf"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def cosine_similarity(X,Y):\n",
        "    \n",
        "    X_list = word_tokenize(X) \n",
        "    Y_list = word_tokenize(Y)\n",
        "    sw = stopwords.words('english') \n",
        "    l1 =[];l2 =[]\n",
        "    X_set = {w for w in X_list if not w in sw} \n",
        "    Y_set = {w for w in Y_list if not w in sw}\n",
        "\n",
        "\n",
        "    rvector = X_set.union(Y_set) \n",
        "    for w in rvector:\n",
        "        if w in X_set: l1.append(1) # create a vector\n",
        "        else: l1.append(0)\n",
        "        if w in Y_set: l2.append(1)\n",
        "        else: l2.append(0)\n",
        "    c = 0\n",
        "\n",
        "\n",
        "    for i in range(len(rvector)):\n",
        "            c+= l1[i]*l2[i]\n",
        "    cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "    return cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB9vILeVkfpy"
      },
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "def sequence_matcher(a, b):\n",
        "  return SequenceMatcher(None, a, b).ratio()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVqYYTxelFSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4135efab-0e14-43b7-8ec9-d51814f5f9ab"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXOj1IVhk59C"
      },
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "def Rouge_Score(hypothesis, reference):\n",
        "  rouge = Rouge()\n",
        "  scores = rouge.get_scores(hypothesis, reference)\n",
        "  \n",
        "  return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol-C5ECSl2tH"
      },
      "source": [
        "def res(a,b):\n",
        "    return len(set(a.split(' ')) & set(b.split(' '))) / float(len(set(a.split(' ')) | set(b.split(' ')))) *100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvPZkZQ8jczF"
      },
      "source": [
        "def aggregate_concat(minutes, transcripts):\n",
        " \n",
        "  # Remove the content within square brackets \n",
        "  minute = remove_cntsqbr(minutes)\n",
        "  transcript = remove_cntsqbr(transcripts)  \n",
        " \n",
        "  # Remove punctutations, stop_words -> Add pos_tag -> Get NNS || NN\n",
        "  Minute_nouns = aggregate_nouns(stop_words, minute)\n",
        "  Transcript_nouns = aggregate_nouns(stop_words, transcript)\n",
        " \n",
        "  minute_str, transcript_str = concat_nouns(Minute_nouns, Transcript_nouns)\n",
        " \n",
        "  cos = cosine_similarity(minute_str, transcript_str)\n",
        "  r_1 = Rouge_Score(minute_str, transcript_str)[0]['rouge-1']['f']\n",
        "  r_l = Rouge_Score(minute_str, transcript_str)[0]['rouge-l']['f']\n",
        "  seq = sequence_matcher(minute_str, transcript_str)\n",
        "  reS = res(minute_str, transcript_str)\n",
        " \n",
        "  return cos, r_1, r_l, seq, reS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gp0oxLQt_Du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0dbdfcd-4b46-4621-f108-82076d88254f"
      },
      "source": [
        "cos, r_1, r_l, seq, reS = aggregate_concat(minutes, transcripts)\n",
        "cos, r_1, r_l, seq, reS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.0, 0.0, 0.009735744089012517, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzyiazvcv6SA",
        "outputId": "41c9ee9f-5876-4d20-e9fe-3ba2125f7d05"
      },
      "source": [
        "print(len(Score_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7usmhcQ9_GO"
      },
      "source": [
        "### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwhU4hlTmckP"
      },
      "source": [
        "import os\n",
        " \n",
        "root_dir = '/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/'\n",
        "train_dir = os.path.join(root_dir, 'train/')\n",
        "dev_dir = os.path.join(root_dir, 'dev/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz1kLwG3mckQ"
      },
      "source": [
        "Score_a, Score_b, Score_c, Score_d, Score_e = [], [], [], [], []\n",
        "\n",
        "for idx, val in enumerate(Labels):\n",
        "  print(f'Iterating over file: {idx}')\n",
        "  try:\n",
        "    minutes = open(minutes_files[idx], 'r').readlines()\n",
        "    transcript = open(transcript_files[idx], 'r').readlines()\n",
        "    cos, r_1, r_l, seq, reS = aggregate_concat(minutes, transcript)\n",
        "    Score_a.append(cos)\n",
        "    Score_b.append(r_1)\n",
        "    Score_c.append(r_l)\n",
        "    Score_d.append(seq)\n",
        "    Score_e.append(reS)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    print('Ignoring this files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N6BHIMXw_rn",
        "outputId": "2022756e-9121-4019-e30b-ac95f80c013d"
      },
      "source": [
        "len(Score_e), len(Score_a), len(Score_b), len(Score_c), len(Score_d), len(Labels), len(score_1_results), len(score_2_results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(843, 843, 843, 843, 843, 843, 843, 843)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGLbx35ttODD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "Score_dataframe = pd.DataFrame({\n",
        "    'Score_1': score_1_results,\n",
        "    'Score_2': score_2_results,\n",
        "    'Cosine_Similarity': Score_a,\n",
        "    'Rouge_1': Score_b,\n",
        "    'Rouge_l' : Score_c,\n",
        "    'Sequence_matcher' : Score_d,\n",
        "    'Res' : Score_e,\n",
        "    'Labels': Labels,\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mVwgHLUKPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "1a8ae843-c9b2-4cb8-d6d6-8e7a6632751c"
      },
      "source": [
        "Score_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score_1</th>\n",
              "      <th>Score_2</th>\n",
              "      <th>Cosine_Similarity</th>\n",
              "      <th>Rouge_1</th>\n",
              "      <th>Rouge_l</th>\n",
              "      <th>Sequence_matcher</th>\n",
              "      <th>Res</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.143019</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.023392</td>\n",
              "      <td>0.008951</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>0.227284</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.079365</td>\n",
              "      <td>0.007048</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3.777778</td>\n",
              "      <td>0.139686</td>\n",
              "      <td>0.056075</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>0.013151</td>\n",
              "      <td>2.884615</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>0.197674</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.018592</td>\n",
              "      <td>8.974359</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.340087</td>\n",
              "      <td>0.241071</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.014851</td>\n",
              "      <td>13.705584</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>1</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>0.181362</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>0.017587</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>0</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.051640</td>\n",
              "      <td>0.029197</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>0.019370</td>\n",
              "      <td>1.481481</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.009060</td>\n",
              "      <td>1.010101</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>0.012589</td>\n",
              "      <td>2.189781</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>1</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>0.044065</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.009259</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.934579</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>843 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Score_1   Score_2  Cosine_Similarity  ...  Sequence_matcher        Res  Labels\n",
              "0          1  3.000000           0.143019  ...          0.008951   3.636364    True\n",
              "1          0  4.200000           0.227284  ...          0.007048   7.692308    True\n",
              "2          0  3.777778           0.139686  ...          0.013151   2.884615    True\n",
              "3          1  1.888889           0.197674  ...          0.018592   8.974359    True\n",
              "4          1  4.000000           0.340087  ...          0.014851  13.705584    True\n",
              "..       ...       ...                ...  ...               ...        ...     ...\n",
              "838        1  3.625000           0.181362  ...          0.017587   7.692308   False\n",
              "839        0  1.800000           0.051640  ...          0.019370   1.481481   False\n",
              "840        0  2.000000           0.071429  ...          0.009060   1.010101   False\n",
              "841        0  2.000000           0.062568  ...          0.012589   2.189781   False\n",
              "842        1  4.666667           0.044065  ...          0.005929   0.934579   False\n",
              "\n",
              "[843 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfHyjA0d0xkW",
        "outputId": "da48ce1e-32f7-437f-fa6e-9248aec12d48"
      },
      "source": [
        "%cd /content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts99jwq51k-2",
        "outputId": "332f4e39-1a85-48aa-ccf1-b0c76bd0d093"
      },
      "source": [
        "%cd /content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzPkPNMN2t27"
      },
      "source": [
        "Score_dataframe.to_csv('task-B-Scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNJQiwge5FK"
      },
      "source": [
        "## Create Dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlBDeqJZNnet"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "Score_dataframe = pd.DataFrame({\n",
        "    'Score_1': score_1_results,\n",
        "    'Score_2': score_2_results,\n",
        "    'Labels' : Labels\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "N9jKHApfgdFT",
        "outputId": "25a27d30-9f79-4157-fd5d-82c450f65df0"
      },
      "source": [
        "# format Score_1, Score_2, Labels\n",
        "Score_dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score_1</th>\n",
              "      <th>Score_2</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2.066667</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2.733333</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2.648649</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>0</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>0</td>\n",
              "      <td>1.833333</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>0</td>\n",
              "      <td>2.750000</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>1</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>843 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Score_1   Score_2  Labels\n",
              "0          1  2.000000    True\n",
              "1          0  2.066667    True\n",
              "2          0  2.600000    True\n",
              "3          1  2.733333    True\n",
              "4          1  2.648649    True\n",
              "..       ...       ...     ...\n",
              "838        0  2.500000   False\n",
              "839        0  1.833333   False\n",
              "840        0  3.000000   False\n",
              "841        0  2.750000   False\n",
              "842        1  4.666667   False\n",
              "\n",
              "[843 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O3cRLX6ZL3J"
      },
      "source": [
        "Score_1 = np.array(Score_dataframe[Score_dataframe['Labels'] == True]['Score_1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-LV4x5DVQ1H",
        "outputId": "10b12736-e7a7-4861-e7bb-1b2477f5a2de"
      },
      "source": [
        "%cd /content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhSU_BQCV_QI"
      },
      "source": [
        "Score_dataframe.to_csv('task-B-Scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Box4T_e8hSAD"
      },
      "source": [
        "## Classification on the task B Scores.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3d7cK9igjzv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing, svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM-YWxcGivZg",
        "outputId": "c2f2c5bc-37bf-42c0-ca0f-31d01df93f34"
      },
      "source": [
        "%cd /content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/automin-2021-confindential-data-main/task-B-en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En8D0tFviLNR"
      },
      "source": [
        "task_B_data = pd.read_csv('task-B-Scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re6FhpFZi5Sx"
      },
      "source": [
        "task_B_data = task_B_data.drop('Unnamed: 0', axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "lcVaXgO-5lKX",
        "outputId": "2d29c042-e41a-4de2-cdc2-648fc5fafd4c"
      },
      "source": [
        "Data = task_B_data\n",
        "Data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score_1</th>\n",
              "      <th>Score_2</th>\n",
              "      <th>Cosine_Similarity</th>\n",
              "      <th>Rouge_1</th>\n",
              "      <th>Rouge_l</th>\n",
              "      <th>Sequence_matcher</th>\n",
              "      <th>Res</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.143019</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.023392</td>\n",
              "      <td>0.008951</td>\n",
              "      <td>3.636364</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>0.227284</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.079365</td>\n",
              "      <td>0.007048</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3.777778</td>\n",
              "      <td>0.139686</td>\n",
              "      <td>0.056075</td>\n",
              "      <td>0.028037</td>\n",
              "      <td>0.013151</td>\n",
              "      <td>2.884615</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.888889</td>\n",
              "      <td>0.197674</td>\n",
              "      <td>0.164706</td>\n",
              "      <td>0.070588</td>\n",
              "      <td>0.018592</td>\n",
              "      <td>8.974359</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.340087</td>\n",
              "      <td>0.241071</td>\n",
              "      <td>0.080357</td>\n",
              "      <td>0.014851</td>\n",
              "      <td>13.705584</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>1</td>\n",
              "      <td>3.625000</td>\n",
              "      <td>0.181362</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>0.017587</td>\n",
              "      <td>7.692308</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>0</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>0.051640</td>\n",
              "      <td>0.029197</td>\n",
              "      <td>0.014599</td>\n",
              "      <td>0.019370</td>\n",
              "      <td>1.481481</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.009060</td>\n",
              "      <td>1.010101</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.062568</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>0.012589</td>\n",
              "      <td>2.189781</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>1</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>0.044065</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.009259</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.934579</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>843 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Score_1   Score_2  Cosine_Similarity  ...  Sequence_matcher        Res  Labels\n",
              "0          1  3.000000           0.143019  ...          0.008951   3.636364    True\n",
              "1          0  4.200000           0.227284  ...          0.007048   7.692308    True\n",
              "2          0  3.777778           0.139686  ...          0.013151   2.884615    True\n",
              "3          1  1.888889           0.197674  ...          0.018592   8.974359    True\n",
              "4          1  4.000000           0.340087  ...          0.014851  13.705584    True\n",
              "..       ...       ...                ...  ...               ...        ...     ...\n",
              "838        1  3.625000           0.181362  ...          0.017587   7.692308   False\n",
              "839        0  1.800000           0.051640  ...          0.019370   1.481481   False\n",
              "840        0  2.000000           0.071429  ...          0.009060   1.010101   False\n",
              "841        0  2.000000           0.062568  ...          0.012589   2.189781   False\n",
              "842        1  4.666667           0.044065  ...          0.005929   0.934579   False\n",
              "\n",
              "[843 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRDHOK4sarT-",
        "outputId": "8a9ff110-0651-4869-da29-67dcfaae0043"
      },
      "source": [
        "True_Labels = [label for label in Data['Labels'] if label ==  True]\n",
        "False_Labels =  [label for label in Data['Labels'] if label ==  False]\n",
        "len(True_Labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9qhy6Oy8Uwp"
      },
      "source": [
        "task_B_data_Actual = pd.read_csv('task-B-Scores.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_VLny6e6pim"
      },
      "source": [
        "Data['Score_2'] = Data['Score_2'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dIheTaR8zUY",
        "outputId": "73eb6102-8237-4ed2-c0f1-cb76d56509fd"
      },
      "source": [
        "Data.head"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      Score_1   Score_2  Cosine_Similarity  ...  Sequence_matcher        Res  Labels\n",
              "0          1  3.000000           0.143019  ...          0.008951   3.636364    True\n",
              "1          0  4.200000           0.227284  ...          0.007048   7.692308    True\n",
              "2          0  3.777778           0.139686  ...          0.013151   2.884615    True\n",
              "3          1  1.888889           0.197674  ...          0.018592   8.974359    True\n",
              "4          1  4.000000           0.340087  ...          0.014851  13.705584    True\n",
              "..       ...       ...                ...  ...               ...        ...     ...\n",
              "838        1  3.625000           0.181362  ...          0.017587   7.692308   False\n",
              "839        0  1.800000           0.051640  ...          0.019370   1.481481   False\n",
              "840        0  2.000000           0.071429  ...          0.009060   1.010101   False\n",
              "841        0  2.000000           0.062568  ...          0.012589   2.189781   False\n",
              "842        1  4.666667           0.044065  ...          0.005929   0.934579   False\n",
              "\n",
              "[843 rows x 8 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rwp0ApSlTuc"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Data.drop(['Labels', 'Score_1'], axis=1), Data['Labels'], test_size=0.33, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8k7B0sxl9A0"
      },
      "source": [
        "### SVC "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_BmCTNk54VO",
        "outputId": "8d74579b-3934-4586-86a1-2c83fdf2c93e"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(kernel=\"rbf\", gamma='auto')\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgnv4ufG6BkD"
      },
      "source": [
        "pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rFG4-C6ykD",
        "outputId": "bd24786c-be09-4c0f-d20f-826c2032cce6"
      },
      "source": [
        "clf.score(X_test, y_test), clf.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8888888888888888, 0.9095744680851063)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybTu1sPB7pkf"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDwyvhKZKKV5",
        "outputId": "3c681608-78b4-44dc-98cd-1bb60b9ae418"
      },
      "source": [
        "confusion_matrix(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[235,   4],\n",
              "       [ 27,  13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYTkSWCGl5XC"
      },
      "source": [
        "###  Random Forst"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzCtzq_FLUFP",
        "outputId": "ee9cf154-8560-4d84-b0e2-afb926ef11bb"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "Classifier = RandomForestClassifier(max_depth=200, random_state=42)\n",
        "Classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=200, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkHWXh5lWq_U"
      },
      "source": [
        "y_pred = Classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB9UJJP8W_MR",
        "outputId": "5de9607d-4359-4ae5-a69b-8695366ef021"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9175627240143369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL5i3OviWvzC",
        "outputId": "fd830cf6-8f42-4ad8-fa5c-15ae8f6f11ad"
      },
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[234,   5],\n",
              "       [ 18,  22]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61SFEpI660d0"
      },
      "source": [
        "### Imbalance Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPsDoivAX2Hl",
        "outputId": "75035df7-07af-4f03-9f63-7535775d1b0d"
      },
      "source": [
        "!pip install imblearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP-LKtBl638Y"
      },
      "source": [
        "from imblearn.over_sampling import SVMSMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS4mr8d665X8",
        "outputId": "18b86ff0-823b-4674-b25c-fffa49ef130f"
      },
      "source": [
        "sm = SVMSMOTE(random_state=42)\n",
        "\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9GWWaon7LE3",
        "outputId": "17dffaa4-29d4-4b63-e2af-fece865e9cc9"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(kernel='rbf', gamma = 'auto')\n",
        "clf.fit(X_res,y_res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7QbQBveYiBa",
        "outputId": "574616a7-b22f-465c-d0dc-0368c0d9e745"
      },
      "source": [
        "print(clf.score(X_test, y_test))\n",
        "\n",
        "pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8207885304659498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzLmGI5Ya1Fv",
        "outputId": "3f395e58-1c27-41b5-a3a0-23a8e45a69b1"
      },
      "source": [
        "confusion_matrix(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[204,  35],\n",
              "       [ 15,  25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUFLiC1grr4N"
      },
      "source": [
        "## Oversample true data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKBE22-frTju",
        "outputId": "a0317619-7abb-449a-c7c5-d772767829a8"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_Train, y_Train = ros.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7RYcpWztRiH",
        "outputId": "a236ee3f-bf98-4500-cada-2d511a9f528a"
      },
      "source": [
        "X_Train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(978, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSszJZLurm3t",
        "outputId": "c5a03b44-0a52-423e-f5ea-b1791a4b4196"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(gamma= 'auto')\n",
        "clf.fit(X_Train,y_Train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-T_gl53tVdN",
        "outputId": "7b88a9ae-2523-450a-afb1-f78def5e33b1"
      },
      "source": [
        "clf.score(X_test, y_test), clf.score(X_Train, y_Train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8279569892473119, 0.8149284253578732)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmnp83emZWpR",
        "outputId": "971bb89e-6876-4732-8d6e-b017c02dba9f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "Classifier = RandomForestClassifier(max_depth=200)\n",
        "Classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=200, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAq_E8RI4Oah"
      },
      "source": [
        "# X_T, X_t, y_T, y_t = train_test_split(X_Train, y_Train, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FznD-ZvZX01",
        "outputId": "649b54e5-c84c-4502-d5b3-147065b0dfe5"
      },
      "source": [
        "Classifier.score(X_test, y_test), Classifier.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.921146953405018, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADZ6t6ZEZexp",
        "outputId": "958a731b-f97d-411e-d645-d67c41651cbf"
      },
      "source": [
        "y_pred = Classifier.predict(X_test)\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[234,   5],\n",
              "       [ 17,  23]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NUHWpgKtzGF",
        "outputId": "0f72ad0d-314d-48f2-9fa9-7e68221e2d32"
      },
      "source": [
        "X_Train[y_Train==True].shape, X_Train[y_Train==False].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((489, 7), (489, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1llgLOI5uyDI",
        "outputId": "236707a0-6e3f-4605-dfd7-f2fe0915da04"
      },
      "source": [
        "X_train[y_train==True].shape, X_train[y_train==False].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((75, 7), (489, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqJE1Ped96Pn"
      },
      "source": [
        "y_pred = Classifier.predict(X_Train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLS1Z1ba-NZ5",
        "outputId": "1b66d876-9904-49b2-bef8-c686e5a0d915"
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_Train, y_pred).ravel()\n",
        "tn, fp, fn, tp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(489, 0, 0, 489)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPqTlCqleVKA"
      },
      "source": [
        "### GDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0ue48QMdhHc",
        "outputId": "a7b221d4-3bd7-414b-a6b3-e97969b7dfb4"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "CLF = GaussianNB()\n",
        "CLF.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lz7Wqt7dvxh"
      },
      "source": [
        "y_Pred = CLF.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4-3fcUFdzbv",
        "outputId": "0b53df59-f304-4672-8b00-e0a197185ba4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test, y_Pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8494623655913979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKuxvz3d806",
        "outputId": "6c78b3ff-104d-46bc-c57d-fc7883ee8c4b"
      },
      "source": [
        "confusion_matrix(y_test, y_Pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[214,  25],\n",
              "       [ 17,  23]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8HhY87oeCIm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}