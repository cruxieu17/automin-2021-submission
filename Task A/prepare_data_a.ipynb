{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data_preprocessing_&_segementation (1).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfNdqoZqbFMA","executionInfo":{"status":"ok","timestamp":1632379845740,"user_tz":-330,"elapsed":23099,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}},"outputId":"96d5ecf0-efce-4d54-b9ae-b374523dff22"},"source":["# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"Nmo-O3wEGnQM","executionInfo":{"status":"ok","timestamp":1632379845743,"user_tz":-330,"elapsed":22,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["import re\n","import json\n","from tqdm import tqdm\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"149_886EoQGW","executionInfo":{"status":"ok","timestamp":1632379845744,"user_tz":-330,"elapsed":19,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# list of regular expression to foarged in transcripts.\n","reg_ex = {\n","      r\"( *)\\<(.*?)\\>\": '',\n","      r\"\\n\": '',\n","      r\"(  +)\": ' ',\n","      r\"\\-\": '',\n","      r\"(,+)\": ',',\n","      r\"( *)(-+)\": '',\n","      r\"\\[\": '',\n","      r\"\\]\": '',\n","}       "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"-G_rprYSe0V2","executionInfo":{"status":"ok","timestamp":1632381620214,"user_tz":-330,"elapsed":374,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# utility methods \n","\n","# open transcript using given file_path\n","def open_transcript(file_path):\n","  document = open(file_path, \"r\").readlines()\n","  return document\n","\n","# remove punctuations and special tokens\n","def rem_ntok(reg_ex, text):\n","  for key, val in reg_ex.items():\n","    text = re.sub(key, val, text)\n","  return text\n","\n","# remove extra space from the text\n","# remove \\n and concat utterance which do not start with (PERSON.*?)\n","def add_colon(sentence):\n","  eidx = re.search(r'\\(PERSON(.*?)\\)', sentence).end()\n","  if sentence[eidx] == ':':\n","    return sentence\n","  else:\n","    return sentence[:eidx] + ':' + sentence[eidx:]\n","\n","# process roles list and remove \"( and )\"\n","def process_roles(role):\n","  regex = {\n","      r\"\\(\": '',\n","      r\"\\)\": ''\n","  }\n","  for key, value in regex.items():\n","    role = re.sub(key, '', role)\n","  return role\n","\n","# remove special tokens from the processed list of roles and utterances\n","def remove_special_tokens(utterance):\n","  regex = [r'^\\.\\',', r'^\\.\\'', r'^\\',', r'^,', r'^\\'', r'^\\.', r'^, ,', r'^\\?']\n","  for exp in regex:\n","    utterance = re.sub(exp, '', utterance)\n","  return utterance\n","\n","# retur max_lenght of list of sentences\n","def max_length(text_list):\n","  length = [len(text.split(' ')) for text in text_list]\n","  return max(length)\n","\n","# remove short utterances precisely \"4\"\n","def preprocess_utterance(sequence):\n","   return_seq = [sentences for sentences in sequence if len(sentences) > 4]\n","   return return_seq\n","\n","# insert extra roles based on generated sentences\n","def insert_to_roles(roles, len, idx, role, con_index):\n","  idx = idx + con_index\n","  for i in range(len):\n","    roles.insert(idx, role)\n","  return roles\n","\n","# text insertion in utterance list at a particular position.\n","def insert_text(utterances, sequences, idx, con_index):\n","  idx = idx + con_index\n","  for text in sequences[::-1]:\n","    utterances.insert(idx, text)\n","  return utterances\n","\n","# check if folder contains transcripts\n","def check_for_transcript(file_list):\n","  for file_ in file_list:\n","    result = re.findall(\"transcript\", file_)\n","    if len(result) == 1:\n","      return file_\n","    else:\n","      pass\n","  return ValueError(\"File not found!\")\n","\n","# convert to json files and save\n","def to_JSON_batch(processed_dict, file_path):\n","  with open(file_path, \"w\") as file_handle:\n","    json.dump(processed_dict, file_handle)\n","\n","def to_JSON_single(processed_dict, file_name, file_path):\n","  out_dict = {file_name: processed_dict}\n","  with open(file_path, \"w\") as file_handle:\n","    json.dump(out_dict, file_handle)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPR2hXCp4YDF","executionInfo":{"status":"ok","timestamp":1632379850568,"user_tz":-330,"elapsed":1617,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# remove newline character\n","def preprocess_transcripts(document):\n","  transcript = []\n","  for line in document:\n","    if line == \"\\n\":\n","      continue\n","    transcript.append(line.replace(\"\\n\", \"\") + \" \")\n","  return transcript\n","\n","# iterate over transcript and segmentation\n","def parse_transcript(reg_ex, transcript):\n","  # updated list of transcript's text\n","  updateList = []\n","  for text in transcript:\n","    updateList.append(rem_ntok(\n","        reg_ex = reg_ex,\n","        text = text\n","    ))\n","  # create list of utterances\n","  utteranceList = []\n","  person_regex = [r'\\(PERSON(.*)\\)']\n","  for text in updateList:\n","    result = re.findall(person_regex[0], text)\n","    if len(result) == 1:\n","      utteranceList.append(add_colon(text))\n","    else:\n","      try:\n","        prev_text = utteranceList[-1]\n","        utteranceList[-1] = prev_text + text.strip() + \" \"\n","      except Exception as e:\n","        pass\n","  return utteranceList\n","\n","# bifurcate transcripts into roles and utterances. \n","def split_transcripts(processed_transcript):\n","  roles, utterances, temp_roles = [], [], []\n","  for text in processed_transcript:\n","    temp = text.split(':')\n","    tune = remove_special_tokens(temp[1].strip()).strip()\n","    tune = remove_special_tokens(tune.strip()).strip()\n","    tune = remove_special_tokens(tune.strip()).strip()\n","    if tune is not '' and len(tune) > 2:\n","      utterances.append(tune)\n","      temp_roles.append(temp[0])\n","  for role in temp_roles:\n","    roles.append(process_roles(role))\n","  return roles, utterances"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aoLXBcwFk60","executionInfo":{"status":"ok","timestamp":1632379857165,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# shortning and splitting utterance sentence and assign roles!\n","\n","def post_process(roles, utterances):\n","  mappings = {\n","      \"idx\": [],\n","      \"utterances\": [],\n","      \"roles\": []\n","  }\n","  for idx, utterance in enumerate(utterances):\n","    word_list = [sentence.strip() for sentence in utterance.split(' ')]\n","    sentence_list = [sentence.strip() for sentence in utterance.split('.')]\n","    # check if length of word list is greater than 150\n","    if len(word_list) > 150:\n","      sequence = []\n","      temp = \"\"\n","      for sentence in sentence_list:\n","        temp = f'{temp} {sentence}.'\n","        # if word limit exceeded than create a new sentence\n","        if len(temp.split(' ')) > 150:\n","          sequence.append(temp.strip())\n","          temp = ''\n","      sequence.append(temp.strip())\n","      # delete the sentence present in original list\n","      del utterances[idx]\n","      # preprocess and striping and removing small sentence less than 3\n","      sequence = preprocess_utterance(sequence)\n","      len_roles = len(sequence)\n","      # retrieve corresponding role from the roles list\n","      role = roles[idx]\n","      # delete the role present in original list\n","      del roles[idx]\n","      # mapping index, roles and utterances to mapping dictionary\n","      mappings[\"idx\"].append(idx)\n","      mappings[\"utterances\"].append(sequence)\n","      mappings[\"roles\"].append(role)\n","  # Applying modifications\n","  con_index = 0\n","  for idx, index in enumerate(mappings['idx']):\n","    sequence = mappings['utterances'][idx]\n","    len_utterances = len(sequence)\n","    utterances = insert_text(utterances, sequence, index, con_index)\n","    roles = insert_to_roles(roles, len_utterances, index, mappings['roles'][idx], con_index)\n","    # Reflecting to the position of insertion\n","    # print(f'Inserted @ {index + con_index}')\n","    con_index = con_index + len_utterances  \n","\n","  # New length after insertion\n","  # print(f'Length of lists after insertion {len(roles), len(utterances)}')\n","\n","  # Applying changes to main dictionary\n","  return roles, utterances"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"1F5BUq5p8wLz","executionInfo":{"status":"ok","timestamp":1632381456113,"user_tz":-330,"elapsed":349,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# process single file\n","def process_single(path_to_file):\n","  document = open_transcript(path_to_file)\n","  transcripts = preprocess_transcripts(document)\n","  transcripts = parse_transcript(reg_ex, transcripts)\n","  roles, utterances = split_transcripts(transcripts)\n","  roles, utterances = post_process(roles, utterances)\n","  trans_dict = {\n","      \"roles\": roles,\n","      \"utterances\": utterances\n","  }\n","  return trans_dict\n","\n","# process batch files/ dataset\n","def batch_process(path_to_folder):\n","  folders = os.listdir(path_to_folder)\n","  main_dict = dict()\n","  for folder in tqdm(folders):\n","    try:\n","      root_folder = path_to_folder + f\"{folder}/\"\n","      files = os.listdir(root_folder)\n","      filename = check_for_transcript(files)\n","      trans_dict = process_single(f\"{root_folder}{filename}\")\n","      main_dict[folder] = trans_dict\n","    except Exception as e:\n","      pass\n","  return main_dict"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yv4-5Sbzaifn","executionInfo":{"status":"ok","timestamp":1632381325319,"user_tz":-330,"elapsed":334,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}},"outputId":"cae01561-5394-4223-a2a0-6c0758239ac1"},"source":["# Sample processing for single transcript\n","path_to_file = \"/content/drive/MyDrive/AutoMin-2021/Datasets/automin-2021-confidential-data/task-A-elitr-minuting-corpus-en/test_II/meeting_en_test_028/transcript_MAN_annot13.deidentified.txt\"\n","trans_dict = process_single(path_to_file)\n","trans_dict.keys()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['roles', 'utterances'])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"uBKv_2lbYyaI"},"source":["trans_dict[\"utterances\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ntkQMDGefeGt","executionInfo":{"status":"ok","timestamp":1632381338672,"user_tz":-330,"elapsed":353,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# save these processed file\n","file_name = 'meeting_en_test_028'\n","to_JSON_single(trans_dict, file_name, \"/content/drive/MyDrive/AutoMin-2021/Datasets/automin-2021-confidential-data/task-A-elitr-minuting-corpus-en/test_II/{}.json\".format(file_name))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5QjxMGQa1J7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632381675990,"user_tz":-330,"elapsed":3702,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}},"outputId":"2cbdd791-4e65-4fb6-cce1-8ca964bcda1f"},"source":["# Sample processing for multiple transcripts\n","path_to_folder = \"/content/drive/MyDrive/AutoMin-2021/Datasets/automin-2021-confidential-data/task-A-elitr-minuting-corpus-en/test_II/\"\n","train_dict = batch_process(path_to_folder)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"Oq9kRgJEh8t1","executionInfo":{"status":"ok","timestamp":1632381689326,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}},"outputId":"97c6be2c-2f1f-426b-e735-df1ac62b149a","colab":{"base_uri":"https://localhost:8080/"}},"source":["train_dict.keys()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['meeting_en_test_028', 'meeting_en_test_019', 'meeting_en_test_020', 'meeting_en_test_023', 'meeting_en_test_022', 'meeting_en_test_025', 'meeting_en_test_021', 'meeting_en_test_024', 'meeting_en_test_026', 'meeting_en_test_027'])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"q7xwDyY-ciCJ","executionInfo":{"status":"ok","timestamp":1632381706045,"user_tz":-330,"elapsed":605,"user":{"displayName":"Kartik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX1EkRQSaMyvaj_D9yV_6t18pvScyhAltL4H3P4g=s64","userId":"05900411542091242466"}}},"source":["# save these processed files\n","to_JSON(train_dict, \"/content/drive/MyDrive/AutoMin-2021/Datasets/automin-2021-confidential-data/task-A-elitr-minuting-corpus-en/test_II/testII.json\")"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNpnoCDWcHDA"},"source":["# **Note files with different format should be handled manually!"],"execution_count":null,"outputs":[]}]}